<html>

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EWB73JXBN5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EWB73JXBN5');
</script>
	
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Homepage of KABI">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Guanting Dong's Homepage|董冠霆的个人主页</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Guanting Dong (董冠霆)&nbsp;</h1></div>
        <h3>Master Student</h3>  
        <p>
            Room 731, 3rd Teaching Building <br>
            Dept. of Artificial Intelligence <br>
            Beijing University of Posts and Telecommunications (BUPT) <br>
            Beijing, China, 100084. <br>
	    WeChat: dongguanting990611 <br>
            Email:  <a href="mailto:dongguanting@bupt.edu.cn">dongguanting@bupt.edu.cn</a> <br>
		
            <a href="https://github.com/dongguanting">[Github]</a>
            <a href="https://scholar.google.com/citations?user=amozZDkAAAAJ&hl=zh-CN&oi=ao">[Google Scholar]</a>
            <a href="https://www.semanticscholar.org/author/Guanting-Dong/51490462?sort=influence">[Semantic Scholar]</a> 
            <a href="https://dblp.org/pid/227/7667.html">[DBLP]</a> 
	    <a href="https://twitter.com/kakakbibibi">[Twitter]</a> 
            <a href="https://www.zhihu.com/people/dong-ge-da-niao-zou-si-fang/posts">[知乎]</a> 

        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="120"></td>
</tr></tbody></table>


<h2>Biography</h2>
    <p>I am a final-year Master student of <a href="https://pris-nlp.github.io/en/#hero">PRIS Lab</a> in the Department of Artificial Intelligence</a>, <a href="https://www.bupt.edu.cn/">Beijing University of Posts and Telecommunications(BUPT)</a>, advised by <a href="https://pris-nlp.github.io/en/author/weiran-xu/">Prof. Weiran Xu</a>. Previously, I also received my B.S. degree from the Department of Information and Communication Engineering, Beijing University of Posts and Telecommunications in July, 2021.</p>
    
    <p> Currently, My research interests focus on 
    <ul>
    
	    <li>
	        <strong>Information Extration and Retrieval</strong>
	    </li>
	    <li>
	        <strong>Reasoning and Alignment for Mathematics, Code and Knowledge Graph</strong>
	    </li>
	    <li>
	        <strong>Interpretability and Robustness for Large Language Models</strong>
	    </li>
	  
     </ul>
<font color="#FF0000">I am preparing intensively for the 24Fall PHD exam. I welcome academic cooperation or LLM internship opportunities in future.</font>
	    
<h2>News</h2>
<ul>
    <li><strong>[2023-12]</strong> Two papers have been accepted by ICASSP 2024! </li>
    <li><strong>[2023-10]</strong> Three paper has been accepted at the EMNLP 2023! </li>
    <li><strong>[2023-08]</strong> Two papers have been accepted by CIKM 2023, Looking forward to seeing you in Birmingham, UK!</li>
</ul>
    


<h2>Research Experiences</h2>
    <ul>
    <li><strong>Alibaba, Qwen Team (ori. Damo Acedemy)</strong>, Algorithm Research Intern. 2023.6 - 2023. 10, Beijing, China</li>
    <li><strong>Meituan, NLP Center</strong>, Algorithm Research Intern. 2022.9 - 2023. 5, Beijing, China</li>
    <li><strong>University of Oxford</strong>, Summer Internship. 2018.7 - 2018.8, Oxford, UK</li>
</ul>

<h2>Hignlight Preprints</h2>
	
<strong>-2024-</strong>

<ul><li><p>DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning<br />
Yejie Wang, Keqing He, <strong>Guanting Dong</strong>, Pei Wang, Weihao Zeng, Muxi Diao, Yutao Mou, Mengdi Zhang, Jingang Wang, Xunliang Cai, Weiran Xu<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2402.09136.pdf'>[paper]</a>
</li>
</ul>

<ul><li><p>PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability<br />
Dayuan Fu, Jianzhao Huang, Siyuan Lu, <strong>Guanting Dong</strong>, Yejie Wang, Keqing He, Weiran Xu<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2402.11534.pdf'>[paper]</a>
    <a href='https://github.com/Fu-Dayuan/PreAct'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Knowledge Editing on Black-box Large Language Models<br />
Xiaoshuai Song, Zhengyang Wang, Keqing He, <strong>Guanting Dong</strong>, Jinxu Zhao, Weiran Xu<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2402.08631.pdf'>[paper]</a>
	<a href='https://github.com/songxiaoshuai/postEdit'>[code]</a> <br>
</li>
</ul>

<strong>-2023-</strong>
	
<ul><li><p>Scaling relationship on learning mathematical reasoning with large language models<br />
    Zheng Yuan, Hongyi Yuan, Chengpeng Li, <strong>Guanting Dong</strong>, Chuanqi Tan, Chang Zhou<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2308.01825.pdf'>[paper]</a>
	<a href='https://github.com/OFA-Sys/gsm8k-ScRel'>[code]</a> <br>
</li>
</ul>
	
<ul><li><p>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition<br />
    <strong>Guanting Dong</strong>, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2310.05492.pdf'>[paper]</a>
</li>
</ul>

<ul><li><p>Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization<br />
Chengpeng Li, Zheng Yuan, Hongyi Yuan, <strong>Guanting Dong</strong>, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2310.05506.pdf'>[paper]</a>
</li>
</ul>	

<ul><li><p>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework<br />
    Shanglin Lei,<strong>Guanting Dong*</strong>, Xiaoping Wang, Keheng Wang, Sirui Wang<br />
    Arxiv. </p>
    <a href='https://arxiv.org/pdf/2309.11911.pdf'>[paper]</a>
    <a href='https://github.com/LIN-SHANG/InstructERC'>[code]</a> <br>
</li>
</ul>
	
	
<h2>Selected Publications</h2>

(* denotes equal contributions)<br>
<strong>-2024-</strong>
	
<ul><li><p>Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment Pre-training for Noisy Slot Filling Task<br />
Jinxu Zhao, <strong>Guanting Dong∗</strong>, Yueyan Qiu, Tingfeng Hui, Xiaoshuai Song, Daichi Guo, Weiran Xu<br />
ICASSP 2024. </p>
<a href='https://arxiv.org/pdf/2402.14494.pdf'>[paper]</a>
</li>
</ul>

	
<strong>-2023-</strong>

<ul><li><p>DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>, Tingfeng Hui, Zhuoma GongQue, Jinxu Zhao, Daichi Guo, Gang Zhao, Keqing He, Weiran Xu<br />
Findings of EMNLP 2023. </p>
<a href='https://aclanthology.org/2023.findings-emnlp.705.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Demo-NSF'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking<br />
Yuxiang Wu, <strong>Guanting Dong*</strong>, Weiran Xu<br />
Findings of EMNLP 2023. </p>
<a href='https://aclanthology.org/2023.findings-emnlp.741.pdf'>[paper]</a>
<a href='https://github.com/ToLightUpTheSky/ParsingDST'>[code]</a> <br>
</li>
</ul>

<ul><li><p>A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER<br />
<strong>Guanting Dong</strong>, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu<br />
CIKM 2023 (Oral). </p>
<a href='https://arxiv.org/pdf/2308.14533.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/MSDP-Fewshot-NER'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA<br />
<strong>Guanting Dong</strong>, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu<br />
CIKM 2023. </p>
<a href='https://arxiv.org/pdf/2308.14436.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/SKP-for-KBQA'>[code]</a> <br>
</li>
</ul>

<ul><li><p>Revisit Input Perturbation Problems for LLMs: A Unified Robustness Evaluation Framework for Noisy Slot Filling Task<br />
<strong>Guanting Dong</strong>,  Jinxu Zhao, Tingfeng Hui, Daichi Guo, Wenlong Wang, Boqi Feng, Yueyan Qiu, Zhuoma Gongque, Keqing He, Zechen Wang, Weiran Xu<br />
NLPCC 2023 (Oral). </p>
<a href='https://arxiv.org/pdf/2310.06504.pdf'>[paper]</a>
<a href='https://github.com/dongguanting/Noise-Slot-Filling-LLM'>[code]</a> <br>
</li>
</ul>


<ul><li><p>Generative Zero-Shot Prompt Learning for Cross-Domain Slot Filling with Inverse Prompting<br />
Xuefeng Li, Liwen Wang, <strong>Guanting Dong*</strong>, Keqing He, Jinzheng Zhao, Hao Lei, Jiachi Liu, Weiran Xu<br />
Findings of ACL 2023. </p>
<a href='https://aclanthology.org/2023.findings-acl.52.pdf'>[paper]</a>
<a href='https://github.com/LiXuefeng2020ai/GZPL'>[code]</a> <br>
</li>
</ul>


<ul><li><p>A Prototypical Semantic Decoupling Method via Joint Contrastive Learning for Few-Shot Named Entity Recognition<br />
<strong>Guanting Dong</strong>, Zechen Wang, Liwen Wang, Daichi Guo, Dayuan Fu, Yuxiang Wu, Chen Zeng, Xuefeng Li, Tingfeng Hui, Keqing He, Xinyue Cui, Qixiang Gao, Weiran Xu<br />
ICASSP 2023. </p>
<a href='https://ieeexplore.ieee.org/abstract/document/10095149'>[paper]</a>
</li>
</ul>

<ul><li><p>Revisit Out-Of-Vocabulary Problem For Slot Filling: A Unified Contrastive Framework With Multi-Level Data Augmentations<br />
Daichi Guo, <strong>Guanting Dong*</strong>, Dayuan Fu, Yuxiang Wu, Chen Zeng, Tingfeng Hui, Liwen Wang, Xuefeng Li, Zechen Wang, Keqing He, Xinyue Cui, Weiran Xu<br />
ICASSP 2023. </p>
<a href='https://ieeexplore.ieee.org/abstract/document/10094766/'>[paper]</a>
</li>
</ul>

<strong>-2022-</strong>

<ul><li><p>Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking<br />
Gao Qixiang, <strong>Guanting Dong*</strong>, Yutao Mou, Liwen Wang, Chen Zeng, Daichi Guo, Mingyang Sun, Weiran Xu<br />
EMNLP 2022 (Oral). </p>
<a href='https://aclanthology.org/2022.emnlp-main.157.pdf'>[paper]</a>
</li>
</ul>


<ul><li><p>Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition<br />
Gang Zhao, <strong>Guanting Dong</strong>, Yidong Shi, Haolong Yan, Weiran Xu, Si Li<br />
Findings of EMNLP 2022. </p>
<a href='https://aclanthology.org/2022.findings-emnlp.473.pdf'>[paper]</a>
<a href='https://github.com/GangZhao98/GEI'>[code]</a> <br>
</li>
</ul>


<ul><li><p>PSSAT: A Perturbed Semantic Structure Awareness Transferring Method for Perturbation-Robust Slot Filling<br />
<strong>Guanting Dong</strong>, Daichi Guo, Liwen Wang, Xuefeng Li, Zechen Wang, Chen Zeng, Keqing He, Jinzheng Zhao, Hao Lei, Xinyue Cui, Yi Huang, Junlan Feng, Weiran Xu<br />
COLING 2022. </p>
<a href='https://aclanthology.org/2022.coling-1.473.pdf'>[paper]</a>
</li>
</ul>






<h2>Honors & Awards</h2>
<ul>
    <!-- <li>
        <strong>China National Scholarship</strong>, 2023.10
    </li> -->
    <li>
        <strong>
            <a href="https://mp.weixin.qq.com/s/FhWj5PFPdgBfzp2QI8F28Q">National Scholarship for Master Students(Top 1%), BUPT.</a>
        </strong>, 2023.10
    </li>
    <li>
        <strong>Outstanding Graduate of Master Students(Top 5%), BUPT.</strong>, 2023.10
    </li>
    <li>
        <strong>Excellent First-class Scholarship for Master Students, BUPT. (Two times)</strong>, 2021, 2022
    </li>
    <li>
        <strong>
        <a href="http://seretod.org/Challenge.html">1st Award on track 2 of SereTOD Challenge, EMNLP 2022</a>
        </strong>, 2022.11
    </li>
    <li>
        <strong>Gold Award for College Music Festival Instrumental Performance, Beijing</strong>, 2021.9
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Honorable Mention</strong>, 2021.4
    </li>

</ul>


<h2>Services</h2>
<strong>Reviewer for</strong>:
<ul>
    
    <li>
        <strong>ACL</strong> 2023
    </li>
    <li>
        <strong>EMNLP</strong> 2023
    </li>
    <li>
        <strong>NAACL</strong> 2023
    </li>
    <li>
        <strong>COLING</strong> 2023
    </li>
</ul>


<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2023 Guanting Dong  <br>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>  
总访问量<span id="busuanzi_value_site_pv"></span>次 <br>
总访客数<span id="busuanzi_value_site_uv"></span>人次
	
</body>

</html>
